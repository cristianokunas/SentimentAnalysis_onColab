{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis-LSTM-BiLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iuj8IAK-NMD0",
        "NmN_QcQz2-9d",
        "sIJGfGzK3lTM",
        "VdQ_29A63lNm",
        "SmXwA5ooEAqu"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOLwVJvHb6QANxJob+w95Fp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cristianokunas/SentimentAnalysis_onColab/blob/main/SentimentAnalysis_LSTM_BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfyTexZtcFy8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6291f4e7-17f2-4169-86cb-04ed3cb443f4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Dec  8 16:58:06 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuj8IAK-NMD0"
      },
      "source": [
        "# Required Downloads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuC8wTIHdIPT"
      },
      "source": [
        "!pip install tensorflow\n",
        "#!pip install tensorflow-gpu==1.14.0\n",
        "!pip install --upgrade tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKPy3eK9dEPU"
      },
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmN_QcQz2-9d"
      },
      "source": [
        "# Etapa 1 - Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIJ9GMLpdTDc"
      },
      "source": [
        "import os, re\n",
        "import time\n",
        "import zipfile\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.utils import plot_model\n",
        "from keras.layers import Dense, Input, Embedding, LSTM, Bidirectional\n",
        "from keras.models import Sequential, Model\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIJGfGzK3lTM"
      },
      "source": [
        "# Etapa 2 - Connecting to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYAMXqQedXmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a6815a-c64a-4132-9b7f-ac11936d56fa"
      },
      "source": [
        "# Conection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdQ_29A63lNm"
      },
      "source": [
        "# Accessing files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oG-TxjMdYk7"
      },
      "source": [
        "# Your path on Google Drive\n",
        "path = \"/content/drive/My Drive/Lab/Data Science/Sentiment Analysis/IMDB/github/imdb.zip\"\n",
        "zip_object = zipfile.ZipFile(file=path, mode=\"r\")\n",
        "zip_object.extractall(\"/content/IMDB\")\n",
        "zip_object.close"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPTslc9n7LNP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7bae8033-e4ce-4ac9-84bf-566ddb1c26ee"
      },
      "source": [
        "# Loads the .csv data file\n",
        "data = pd.read_csv('/content/IMDB/imdb.csv')\n",
        "data.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text sentiment\n",
              "0  Once again Mr. Costner has dragged out a movie...       neg\n",
              "1  This is an example of why the majority of acti...       neg\n",
              "2  First of all I hate those moronic rappers, who...       neg\n",
              "3  Not even the Beatles could write songs everyon...       neg\n",
              "4  Brass pictures (movies is not a fitting word f...       neg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEhzCSv5Eb-u"
      },
      "source": [
        "# Etapa 4 - Initializes variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eUlMAiadh3U"
      },
      "source": [
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "# The model will be exported to this file\n",
        "# For LSTM\n",
        "filename = '/content/IMDB/model_saved_lstm.h5'\n",
        "# For BiLSTM\n",
        "# filename = '/content/IMDB/model/model_saved_bilstm.h5'\n",
        "\n",
        "bilstm = False\n",
        "\n",
        "# Number of iterations\n",
        "epochs = 2\n",
        "\n",
        "# Dimensionality of pre-trained word embedding\n",
        "word_embedding_dim = 300\n",
        "\n",
        "# Number of samples to be used in each gradient update - number of instances\n",
        "batch_size = 1024\n",
        "\n",
        "# Separates % for model testing\n",
        "test_dim = 0.20\n",
        "\n",
        "# Maximum number of words to keep in the vocabulary\n",
        "max_features = 20000\n",
        "\n",
        "# Embedding layer output dimension\n",
        "embed_dim = 128\n",
        "\n",
        "# Maximum size of sentences\n",
        "max_sequence_length = 300"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81tYf1TI3ze0"
      },
      "source": [
        "# Etapa 5 - Data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgAPa9px33R0"
      },
      "source": [
        "def calcRuntime(totalTime):\n",
        "  hour, rem = divmod(totalTime, 3600)\n",
        "  minutes, seconds = divmod(rem, 60)\n",
        "  formatTime = \"{:0>2}:{:0>2}:{:05.2f}\".format(int(hour),int(minutes),seconds)\n",
        "  return formatTime\n",
        "\n",
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)\n",
        "\n",
        "# Method for clearing strings\n",
        "# Removes non-meaningful content\n",
        "def clean_str(string):\n",
        "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    string = re.sub(r'RT+', '', string) \n",
        "    string = re.sub(r'@\\S+', '', string)  \n",
        "    string = re.sub(r'http\\S+', '', string)\n",
        "\n",
        "    cleanr = re.compile('<.*?>')\n",
        "\n",
        "    string = re.sub(r'\\d+', '', string)\n",
        "    string = re.sub(cleanr, '', string)\n",
        "    string = re.sub(\"'\", '', string)\n",
        "    string = re.sub(r'\\W+', ' ', string)\n",
        "    \n",
        "    string = string.replace('_', '')\n",
        "\n",
        "    string = remove_emoji(string)\n",
        "\n",
        "    return string.strip().lower()\n",
        "\n",
        "# Method for preparing training and test data\n",
        "# loads .csv, clears strings and removes stop_wors\n",
        "# Tokenization\n",
        "def prepare_data(data):\n",
        "    data = data[['text', 'sentiment']]\n",
        "    data['text'] = data['text'].apply(lambda x: clean_str(x))\n",
        "    data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))\n",
        "\n",
        "    stop_words = set(stopwords.words('portuguese'))\n",
        "    text = []\n",
        "    for row in data['text'].values:\n",
        "        word_list = text_to_word_sequence(row)\n",
        "        no_stop_words = [w for w in word_list if not w in stop_words]\n",
        "        no_stop_words = \" \".join(no_stop_words)\n",
        "        text.append(no_stop_words)\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    X = tokenizer.texts_to_sequences(text)\n",
        "\n",
        "    X = pad_sequences(X, maxlen=max_sequence_length)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    Y = pd.get_dummies(data['sentiment']).values\n",
        "\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_dim, random_state=42)\n",
        "    print('Número de sentenças do conjunto de treinamento: ', len(X_train))\n",
        "    print('Número de sentenças do conjunto de teste: ', len(X_test))\n",
        "\n",
        "    return X_train, X_test, Y_train, Y_test, word_index, tokenizer"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgVZqVV3O_gK"
      },
      "source": [
        "# Etapa 6b - Create model - functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORjmYhzJ1LLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b277c192-817e-4537-edf6-c1b82351285c"
      },
      "source": [
        "# Calls method to prepare data\n",
        "X_train, X_test, Y_train, Y_test, word_index, tokenizer = prepare_data(data)\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_test.shape, Y_test.shape)\n",
        "\n",
        "# Specifies which device to run\n",
        "with tf.device(\"/gpu:0\"):\n",
        "  \n",
        "  # create\n",
        "  input_shape = (max_sequence_length,)\n",
        "  model_input = Input(shape=input_shape, name=\"input\", dtype='int32')\n",
        "  embedding = Embedding(max_features, embed_dim, \n",
        "                input_length=max_sequence_length, name=\"embedding\")(model_input)\n",
        "  if bilstm is True:\n",
        "    lstm = Bidirectional(LSTM(embed_dim, dropout=0.2, recurrent_dropout=0.2, name=\"lstm\"))(embedding)\n",
        "  else:\n",
        "    lstm = LSTM(embed_dim, dropout=0.2, recurrent_dropout=0.2, name=\"lstm\")(embedding)\n",
        "\n",
        "  model_output = Dense(units=128, input_dim=64, kernel_initializer='uniform', activation='relu')(lstm)\n",
        "  model_output = Dense(units=64, kernel_initializer='uniform', activation='relu')(model_output)\n",
        "  model_output = Dense(units=2, kernel_initializer='uniform', activation='sigmoid')(model_output)\n",
        "  model = Model(inputs=model_input, outputs=model_output)\n",
        "\n",
        "  # compile\n",
        "  model.compile(loss='binary_crossentropy', \n",
        "                optimizer='adam', \n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  print(model.summary())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número de sentenças do conjunto de treinamento:  40000\n",
            "Número de sentenças do conjunto de teste:  10000\n",
            "(40000, 300) (40000, 2)\n",
            "(10000, 300) (10000, 2)\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 300)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 300, 128)          2560000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,716,482\n",
            "Trainable params: 2,716,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOdEiE1tCO9N"
      },
      "source": [
        "# Etapa 7 - Training the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9zQWzwxafQe"
      },
      "source": [
        "Neural network training\n",
        "\n",
        "Checks whether a trained model exists\n",
        "\n",
        "True = load the model already trained\n",
        "\n",
        "False = trains the network and saves the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5bb9PDI4x4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b91d86c3-fc6a-4178-bdce-abd9fe76c71a"
      },
      "source": [
        "# Specifies which device to run\n",
        "with tf.device(\"/gpu:0\"):\n",
        "\n",
        "  if os.path.exists('{}'.format(filename)):\n",
        "    try:\n",
        "      model.load_weights('{}'.format(filename))\n",
        "      print('Successful model loading!')\n",
        "    except:\n",
        "      print('No such file or directory!')\n",
        "  else:\n",
        "    inicio = time.time()\n",
        "    hist = model.fit(\n",
        "        X_train,\n",
        "        Y_train,\n",
        "        validation_data=(X_test, Y_test),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        verbose=1)\n",
        "    \n",
        "    fim = time.time()\n",
        "    model.save_weights(filename)\n",
        "  \n",
        "  print(calcRuntime(fim - inicio))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "40/40 [==============================] - 52s 1s/step - loss: 0.2734 - accuracy: 0.8919 - val_loss: 0.3011 - val_accuracy: 0.8790\n",
            "Epoch 2/2\n",
            "40/40 [==============================] - 53s 1s/step - loss: 0.1921 - accuracy: 0.9305 - val_loss: 0.2963 - val_accuracy: 0.8934\n",
            "00:01:47.66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAoHkwn132L8"
      },
      "source": [
        "# Etapa 8 - Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELAiM4jwD_oE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47481ab4-8be4-4c70-fc8a-a712b6823104"
      },
      "source": [
        "# Evaluating the model\n",
        "scores = model.evaluate(\n",
        "    X_test, Y_test, \n",
        "    verbose=0, \n",
        "    batch_size=batch_size)\n",
        "\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))\n",
        "print(\"Erro: %.2f%%\" % (scores[0] * 100))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 89.34%\n",
            "Erro: 29.63%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Yc8xXbF21v3"
      },
      "source": [
        "### Validate model with new entries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgMajaLc44As",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc2c022-d35c-49c8-c79e-1eb077036761"
      },
      "source": [
        "while True:\n",
        "    print(\"\\nType 0 to quit\")\n",
        "    sentence = input(\"input> \")\n",
        "\n",
        "    if sentence == \"0\":\n",
        "        break\n",
        "\n",
        "    new_text = [sentence]\n",
        "    new_text = tokenizer.texts_to_sequences(new_text)\n",
        "\n",
        "    new_text = pad_sequences(new_text, maxlen=max_sequence_length, dtype='int32', value=0)\n",
        "\n",
        "    sentiment = model.predict(new_text, batch_size=1, verbose=2)[0]\n",
        "\n",
        "    print(np.argmax(sentiment))\n",
        "    if (np.argmax(sentiment) == 0):\n",
        "        pred_proba = \"%.2f%%\" % (sentiment[0] * 100)\n",
        "        print(\"negativo => \", pred_proba)\n",
        "    elif (np.argmax(sentiment) == 1):\n",
        "        pred_proba = \"%.2f%%\" % (sentiment[1] * 100)\n",
        "        print(\"positivo => \", pred_proba)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Type 0 to quit\n",
            "input> There isn't too much in the way of suspense or surprises when it comes to the story, but there are some shocking moments and funny lines in this epic finale. Again, like many of the best Marvel films, the holes and flaws are covered up with humor and fan service, making everything okay. That being said, I did prefer Infinity War to this film, which really misses the leads of the other Marvel franchises that were \"snapped\" out. Overall, however, there are only a few ways you can wrap up the main story of the MCU, and this was a solid direction.\n",
            "1/1 - 0s\n",
            "1\n",
            "positivo =>  98.39%\n",
            "\n",
            "Type 0 to quit\n",
            "input> I had no choice but to watch it to finish the sequence. The worst of all the Avengers movies. Apart from some action scenes all the rest it is pure lame dialogues and poor performances. Purely made to make money out of a \"trendy\" public that are rating this movie high because I've never met one single person who has read the comics and like this garbage. At least, there will be no more of this, I hope.\n",
            "1/1 - 0s\n",
            "0\n",
            "negativo =>  99.37%\n",
            "\n",
            "Type 0 to quit\n",
            "input> 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTtTmsr8h6Hs"
      },
      "source": [
        "### **Review**:\n",
        ">There isn't too much in the way of suspense or surprises when it comes to the story, but there are some shocking moments and funny lines in this epic finale. Again, like many of the best Marvel films, the holes and flaws are covered up with humor and fan service, making everything okay. That being said, I did prefer Infinity War to this film, which really misses the leads of the other Marvel franchises that were \"snapped\" out. Overall, however, there are only a few ways you can wrap up the main story of the MCU, and this was a solid direction.\n",
        "\n",
        ">**Opinion: 8/10 stars**\n",
        "\n",
        "---\n",
        "\n",
        "### **Review**:\n",
        ">I had no choice but to watch it to finish the sequence. The worst of all the Avengers movies. Apart from some action scenes all the rest it is pure lame dialogues and poor performances. Purely made to make money out of a \"trendy\" public that are rating this movie high because I've never met one single person who has read the comics and like this garbage. At least, there will be no more of this, I hope.\n",
        "\n",
        ">**Opinion: 1/10 stars**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmXwA5ooEAqu"
      },
      "source": [
        "# Final - Unmount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqsyKrc6dlYc"
      },
      "source": [
        "drive.flush_and_unmount()\n",
        "print('All changes made in this colab session should now be visible in Drive.')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}